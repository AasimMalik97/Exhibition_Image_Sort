{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 112\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 112\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[11], line 108\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_file \u001b[38;5;129;01min\u001b[39;00m input_files:\n\u001b[0;32m    107\u001b[0m     output_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(input_file)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_output.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m--> 108\u001b[0m     process_and_output(input_file, output_file)\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 86\u001b[0m, in \u001b[0;36mprocess_and_output\u001b[1;34m(file_path, output_file_path)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_and_output\u001b[39m(file_path, output_file_path):\n\u001b[0;32m     85\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Process input and write the output to a file.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     frameglasses \u001b[38;5;241m=\u001b[39m process_paintings(file_path)\n\u001b[0;32m     87\u001b[0m     ordered_frameglasses, max_score \u001b[38;5;241m=\u001b[39m greedy_ordering_optimized(frameglasses)\n\u001b[0;32m     88\u001b[0m     num_frameglasses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ordered_frameglasses)\n",
      "Cell \u001b[1;32mIn[11], line 79\u001b[0m, in \u001b[0;36mprocess_paintings\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     76\u001b[0m         portraits\u001b[38;5;241m.\u001b[39mappend(([idx], \u001b[38;5;28mset\u001b[39m(painting[\u001b[38;5;241m2\u001b[39m:])))\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Pair portraits using the optimized method\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m portrait_frameglasses \u001b[38;5;241m=\u001b[39m pair_portraits_optimized(portraits)\n\u001b[0;32m     80\u001b[0m landscape_frameglasses \u001b[38;5;241m=\u001b[39m landscapes\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m portrait_frameglasses \u001b[38;5;241m+\u001b[39m landscape_frameglasses\n",
      "Cell \u001b[1;32mIn[11], line 20\u001b[0m, in \u001b[0;36mpair_portraits_optimized\u001b[1;34m(portraits)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(portraits)):\n\u001b[0;32m     19\u001b[0m         diversity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(portraits[i][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m|\u001b[39m portraits[j][\u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Union of tags\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m         heapq\u001b[38;5;241m.\u001b[39mheappush(heap, (\u001b[38;5;241m-\u001b[39mdiversity, i, j))  \u001b[38;5;66;03m# Max heap using negative diversity\u001b[39;00m\n\u001b[0;32m     22\u001b[0m paired \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m heap \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(paired) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(portraits):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import heapq\n",
    "\n",
    "def calculate_local_satisfaction(f1, f2):\n",
    "    \"\"\"Calculate the Local Robotic Satisfaction between two frameglasses.\"\"\"\n",
    "    common = len(f1 & f2)\n",
    "    f1_diff = len(f1 - f2)\n",
    "    f2_diff = len(f2 - f1)\n",
    "    return min(common, f1_diff, f2_diff)\n",
    "\n",
    "def pair_portraits_optimized(portraits):\n",
    "    \"\"\"Pair portraits efficiently using a heap to maximize diversity.\"\"\"\n",
    "    portrait_frameglasses = []\n",
    "    heap = []\n",
    "\n",
    "    # Precompute all possible pair diversities and store in a heap\n",
    "    for i in range(len(portraits)):\n",
    "        for j in range(i + 1, len(portraits)):\n",
    "            diversity = len(portraits[i][1] | portraits[j][1])  # Union of tags\n",
    "            heapq.heappush(heap, (-diversity, i, j))  # Max heap using negative diversity\n",
    "\n",
    "    paired = set()\n",
    "    while heap and len(paired) < len(portraits):\n",
    "        _, i, j = heapq.heappop(heap)\n",
    "        if i not in paired and j not in paired:\n",
    "            combined_indices = portraits[i][0] + portraits[j][0]\n",
    "            combined_tags = portraits[i][1] | portraits[j][1]\n",
    "            portrait_frameglasses.append((combined_indices, combined_tags))\n",
    "            paired.add(i)\n",
    "            paired.add(j)\n",
    "\n",
    "    # Add any leftover single portraits as frameglasses\n",
    "    for idx in range(len(portraits)):\n",
    "        if idx not in paired:\n",
    "            portrait_frameglasses.append(portraits[idx])\n",
    "\n",
    "    return portrait_frameglasses\n",
    "\n",
    "def greedy_ordering_optimized(frameglasses):\n",
    "    \"\"\"Order frameglasses greedily with reduced complexity.\"\"\"\n",
    "    ordered = [frameglasses.pop(0)]  # Start with the first frameglass\n",
    "    total_score = 0\n",
    "\n",
    "    while frameglasses:\n",
    "        # Precompute similarities with the current frameglass\n",
    "        similarities = [\n",
    "            (calculate_local_satisfaction(ordered[-1][1], f[1]), idx, f)\n",
    "            for idx, f in enumerate(frameglasses)\n",
    "        ]\n",
    "\n",
    "        # Pick the best next frameglass\n",
    "        best_score, best_index, best_frameglass = max(similarities)\n",
    "        ordered.append(best_frameglass)\n",
    "        total_score += best_score\n",
    "        frameglasses.pop(best_index)\n",
    "\n",
    "    return ordered, total_score\n",
    "\n",
    "def process_paintings(file_path):\n",
    "    \"\"\"Read and process paintings from the input file.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    paintings = []\n",
    "    for line in lines[1:]:\n",
    "        parts = line.strip().split()\n",
    "        paintings.append([parts[0], int(parts[1]), *parts[2:]])\n",
    "\n",
    "    landscapes = []\n",
    "    portraits = []\n",
    "\n",
    "    for idx, painting in enumerate(paintings):\n",
    "        if painting[0] == 'L':\n",
    "            landscapes.append(([idx], set(painting[2:])))\n",
    "        elif painting[0] == 'P':\n",
    "            portraits.append(([idx], set(painting[2:])))\n",
    "\n",
    "    # Pair portraits using the optimized method\n",
    "    portrait_frameglasses = pair_portraits_optimized(portraits)\n",
    "    landscape_frameglasses = landscapes\n",
    "\n",
    "    return portrait_frameglasses + landscape_frameglasses\n",
    "\n",
    "def process_and_output(file_path, output_file_path):\n",
    "    \"\"\"Process input and write the output to a file.\"\"\"\n",
    "    frameglasses = process_paintings(file_path)\n",
    "    ordered_frameglasses, max_score = greedy_ordering_optimized(frameglasses)\n",
    "    num_frameglasses = len(ordered_frameglasses)\n",
    "    \n",
    "    # Write output to file\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        f.write(f\"{max_score}\\n\")  # Write the total score\n",
    "        f.write(f\"{num_frameglasses}\\n\")  # Write the number of frameglasses\n",
    "        for frameglass in ordered_frameglasses:\n",
    "            f.write(' '.join(map(str, frameglass[0])) + '\\n')  # Write indices of the paintings\n",
    "\n",
    "# Main Function\n",
    "def main():\n",
    "    # Define input and output file paths\n",
    "    input_files = [\n",
    "       \"./Data/11_randomizing_paintings.txt\",\n",
    "    ]\n",
    "    output_dir = \"output_files\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for input_file in input_files:\n",
    "        output_file = os.path.join(output_dir, os.path.basename(input_file).replace(\".txt\", \"_output.txt\"))\n",
    "        process_and_output(input_file, output_file)\n",
    "        print(f\"Processed {input_file}, output saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed ./Data/10_computable_moments.txt, output saved to output_files\\10_computable_moments_output.txt\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    main()\n",
    "    profiler.disable()\n",
    "    \n",
    "    # Save the profiling results to a file\n",
    "    with open(\"profile_results.txt\", \"w\") as f:\n",
    "        stats = pstats.Stats(profiler, stream=f)\n",
    "        stats.strip_dirs()\n",
    "        stats.sort_stats(\"cumulative\")\n",
    "        stats.print_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed ./Data/10_computable_moments.txt, output saved to output_files\\10_computable_moments_output_advanced.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import heapq\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Helper Functions\n",
    "def calculate_local_satisfaction(f1, f2):\n",
    "    \"\"\"Calculate the Local Robotic Satisfaction between two frameglasses.\"\"\"\n",
    "    common = len(f1 & f2)\n",
    "    f1_diff = len(f1 - f2)\n",
    "    f2_diff = len(f2 - f1)\n",
    "    return min(common, f1_diff, f2_diff)\n",
    "\n",
    "# Precompute Similarities Using Hashmap\n",
    "def precompute_similarities(frameglasses):\n",
    "    \"\"\"Precompute similarities between all frameglasses.\"\"\"\n",
    "    similarity_map = {}\n",
    "    for i in range(len(frameglasses)):\n",
    "        for j in range(i + 1, len(frameglasses)):\n",
    "            similarity = calculate_local_satisfaction(frameglasses[i][1], frameglasses[j][1])\n",
    "            similarity_map[(i, j)] = similarity\n",
    "    return similarity_map\n",
    "\n",
    "# Greedy Ordering with Hashmap\n",
    "def greedy_ordering_with_hashmap(frameglasses):\n",
    "    \"\"\"Order frameglasses greedily using precomputed similarities.\"\"\"\n",
    "    similarity_map = precompute_similarities(frameglasses)\n",
    "    ordered = [frameglasses.pop(0)]  # Start with the first frameglass\n",
    "    total_score = 0\n",
    "\n",
    "    while frameglasses:\n",
    "        # Find the best next frameglass using the hashmap\n",
    "        best_score, best_index, best_frameglass = max(\n",
    "            ((similarity_map.get((ordered[-1][0][0], f[0][0]), 0), idx, f)\n",
    "             for idx, f in enumerate(frameglasses)),\n",
    "            key=lambda x: x[0]\n",
    "        )\n",
    "\n",
    "        ordered.append(best_frameglass)\n",
    "        total_score += best_score\n",
    "        frameglasses.pop(best_index)\n",
    "\n",
    "    return ordered, total_score\n",
    "\n",
    "# Graph-Based Representation\n",
    "def build_similarity_graph(frameglasses):\n",
    "    \"\"\"Build a graph where nodes are frameglasses and edges are similarities.\"\"\"\n",
    "    graph = nx.Graph()\n",
    "    for i in range(len(frameglasses)):\n",
    "        graph.add_node(i, frameglass=frameglasses[i])\n",
    "    for i in range(len(frameglasses)):\n",
    "        for j in range(i + 1, len(frameglasses)):\n",
    "            similarity = calculate_local_satisfaction(frameglasses[i][1], frameglasses[j][1])\n",
    "            graph.add_edge(i, j, weight=similarity)\n",
    "    return graph\n",
    "\n",
    "# Optimized Ordering Using a Minimum Spanning Tree (MST)\n",
    "def order_with_graph_mst(frameglasses):\n",
    "    \"\"\"Order frameglasses using a graph and minimum spanning tree.\"\"\"\n",
    "    graph = build_similarity_graph(frameglasses)\n",
    "    mst = nx.minimum_spanning_tree(graph, weight='weight')\n",
    "\n",
    "    # Traverse the MST to determine the order\n",
    "    ordered_indices = list(nx.dfs_preorder_nodes(mst))\n",
    "    ordered = [frameglasses[i] for i in ordered_indices]\n",
    "\n",
    "    # Compute total score\n",
    "    total_score = sum(graph[u][v]['weight'] for u, v in zip(ordered_indices, ordered_indices[1:]))\n",
    "    return ordered, total_score\n",
    "\n",
    "# Clustering Portraits to Reduce Complexity\n",
    "def vectorize_tags(tag_sets):\n",
    "    \"\"\"Convert tag sets into vectorized format using TF-IDF.\"\"\"\n",
    "    tag_strings = [\" \".join(tags) for tags in tag_sets]\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    return vectorizer.fit_transform(tag_strings)\n",
    "\n",
    "def cluster_portraits(portraits, num_clusters=10):\n",
    "    \"\"\"Cluster portraits into groups based on their tags.\"\"\"\n",
    "    tag_sets = [p[1] for p in portraits]\n",
    "    vectors = vectorize_tags(tag_sets)\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42).fit(vectors)\n",
    "    cluster_labels = kmeans.labels_\n",
    "\n",
    "    clusters = {i: [] for i in range(num_clusters)}\n",
    "    for idx, label in enumerate(cluster_labels):\n",
    "        clusters[label].append(portraits[idx])\n",
    "\n",
    "    return clusters\n",
    "\n",
    "def pair_portraits_with_clustering(portraits, num_clusters=10):\n",
    "    \"\"\"Pair portraits using clustering to reduce comparisons.\"\"\"\n",
    "    clusters = cluster_portraits(portraits, num_clusters)\n",
    "    paired_frameglasses = []\n",
    "\n",
    "    for cluster in clusters.values():\n",
    "        if len(cluster) > 1:\n",
    "            # Pair within the cluster\n",
    "            paired_frameglasses.extend(pair_portraits_optimized(cluster))\n",
    "        elif len(cluster) == 1:\n",
    "            # Add single portrait directly\n",
    "            paired_frameglasses.append(cluster[0])\n",
    "\n",
    "    return paired_frameglasses\n",
    "\n",
    "# Pairing Portraits Using a Heap\n",
    "def pair_portraits_optimized(portraits):\n",
    "    \"\"\"Pair portraits efficiently using a heap to maximize diversity.\"\"\"\n",
    "    portrait_frameglasses = []\n",
    "    heap = []\n",
    "\n",
    "    for i in range(len(portraits)):\n",
    "        for j in range(i + 1, len(portraits)):\n",
    "            diversity = len(portraits[i][1] | portraits[j][1])\n",
    "            heapq.heappush(heap, (-diversity, i, j))\n",
    "\n",
    "    paired = set()\n",
    "    while heap and len(paired) < len(portraits):\n",
    "        _, i, j = heapq.heappop(heap)\n",
    "        if i not in paired and j not in paired:\n",
    "            combined_indices = portraits[i][0] + portraits[j][0]\n",
    "            combined_tags = portraits[i][1] | portraits[j][1]\n",
    "            portrait_frameglasses.append((combined_indices, combined_tags))\n",
    "            paired.add(i)\n",
    "            paired.add(j)\n",
    "\n",
    "    for idx in range(len(portraits)):\n",
    "        if idx not in paired:\n",
    "            portrait_frameglasses.append(portraits[idx])\n",
    "\n",
    "    return portrait_frameglasses\n",
    "\n",
    "# Painting Processing\n",
    "def process_paintings(file_path, num_clusters=10):\n",
    "    \"\"\"Process paintings with optimized pairing and ordering.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    paintings = []\n",
    "    for line in lines[1:]:\n",
    "        parts = line.strip().split()\n",
    "        paintings.append([parts[0], int(parts[1]), *parts[2:]])\n",
    "\n",
    "    landscapes = []\n",
    "    portraits = []\n",
    "\n",
    "    for idx, painting in enumerate(paintings):\n",
    "        if painting[0] == 'L':\n",
    "            landscapes.append(([idx], set(painting[2:])))\n",
    "        elif painting[0] == 'P':\n",
    "            portraits.append(([idx], set(painting[2:])))\n",
    "\n",
    "    portrait_frameglasses = pair_portraits_with_clustering(portraits, num_clusters)\n",
    "    landscape_frameglasses = landscapes\n",
    "\n",
    "    return portrait_frameglasses + landscape_frameglasses\n",
    "\n",
    "# Optimized Output Process\n",
    "def process_and_output_advanced(file_path, output_file_path, use_graph=False):\n",
    "    \"\"\"Process input and write the output using advanced data structures.\"\"\"\n",
    "    frameglasses = process_paintings(file_path)\n",
    "    if use_graph:\n",
    "        ordered_frameglasses, max_score = order_with_graph_mst(frameglasses)\n",
    "    else:\n",
    "        ordered_frameglasses, max_score = greedy_ordering_with_hashmap(frameglasses)\n",
    "\n",
    "    num_frameglasses = len(ordered_frameglasses)\n",
    "\n",
    "    # Write output to file\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        f.write(f\"{max_score}\\n\")  # Write the total score\n",
    "        f.write(f\"{num_frameglasses}\\n\")  # Write the number of frameglasses\n",
    "        for frameglass in ordered_frameglasses:\n",
    "            f.write(' '.join(map(str, frameglass[0])) + '\\n')\n",
    "\n",
    "# Main Function\n",
    "def main():\n",
    "    input_files = [\"./Data/10_computable_moments.txt\"]\n",
    "    output_dir = \"output_files\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for input_file in input_files:\n",
    "        output_file = os.path.join(output_dir, os.path.basename(input_file).replace(\".txt\", \"_output_advanced.txt\"))\n",
    "        process_and_output_advanced(input_file, output_file, use_graph=True)\n",
    "        print(f\"Processed {input_file}, output saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
