{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "from itertools import permutations\n",
    "\n",
    "DATA_DIR = \"./Data\"  # Adjust if your input files are in a different directory\n",
    "\n",
    "def read_input(file_name):\n",
    "    \"\"\"Reads and parses the input file.\"\"\"\n",
    "    file_path = os.path.join(DATA_DIR, file_name)\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # First line contains the number of paintings\n",
    "    n = int(lines[0].strip())\n",
    "    paintings = []\n",
    "    \n",
    "    # Process each painting line\n",
    "    for i, line in enumerate(lines[1:], start=0):\n",
    "        parts = line.strip().split()\n",
    "        orientation = parts[0]\n",
    "        num_tags = int(parts[1])\n",
    "        tags = set(parts[2:])  # Use a set to ensure uniqueness of tags\n",
    "        paintings.append({\"ID\": i, \"Orientation\": orientation, \"Tags\": tags})\n",
    "    \n",
    "    return n, paintings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frameglasses(paintings):\n",
    "    \"\"\"\n",
    "    Generates frameglasses from paintings:\n",
    "    - Each Landscape (L) is in its own frameglass.\n",
    "    - Each frameglass for Portraits (P) combines exactly two paintings.\n",
    "    - Tags in a frameglass are unique.\n",
    "    \"\"\"\n",
    "    landscapes = [p for p in paintings if p[\"Orientation\"] == \"L\"]\n",
    "    portraits = [p for p in paintings if p[\"Orientation\"] == \"P\"]\n",
    "\n",
    "    frameglasses = []\n",
    "\n",
    "    # Add each Landscape as its own frameglass\n",
    "    for landscape in landscapes:\n",
    "        frameglasses.append({\n",
    "            \"Paintings\": [landscape[\"ID\"]],  # Only one Landscape painting per frameglass\n",
    "            \"Tags\": landscape[\"Tags\"]  # Tags remain as-is\n",
    "        })\n",
    "\n",
    "    # Group every two Portraits together\n",
    "    for i in range(0, len(portraits), 2):\n",
    "        if i + 1 < len(portraits):  # Ensure there is a pair\n",
    "            combined_tags = portraits[i][\"Tags\"] | portraits[i + 1][\"Tags\"]  # Combine unique tags\n",
    "            frameglasses.append({\n",
    "                \"Paintings\": [portraits[i][\"ID\"], portraits[i + 1][\"ID\"]],\n",
    "                \"Tags\": combined_tags\n",
    "            })\n",
    "        else:\n",
    "            # If there is an odd number of Portraits, leave the last one ungrouped (optional)\n",
    "            frameglasses.append({\n",
    "                \"Paintings\": [portraits[i][\"ID\"]],\n",
    "                \"Tags\": portraits[i][\"Tags\"]\n",
    "            })\n",
    "\n",
    "    return frameglasses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(frameglasses):\n",
    "    \"\"\"Calculates the Global Robotic Satisfaction.\"\"\"\n",
    "    score = 0\n",
    "    for i in range(len(frameglasses) - 1):\n",
    "        tags1 = frameglasses[i][\"Tags\"]\n",
    "        tags2 = frameglasses[i + 1][\"Tags\"]\n",
    "\n",
    "        # Calculate Local Robotic Satisfaction\n",
    "        common_tags = len(tags1 & tags2)\n",
    "        tags_in_f1_not_in_f2 = len(tags1 - tags2)\n",
    "        tags_in_f2_not_in_f1 = len(tags2 - tags1)\n",
    "        local_score = min(common_tags, tags_in_f1_not_in_f2, tags_in_f2_not_in_f1)\n",
    "        score += local_score\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "import numpy as np\n",
    "\n",
    "def compute_pair(args):\n",
    "    try:\n",
    "        i, j, frameglasses = args\n",
    "        tags_i = frameglasses[i][\"Tags\"]\n",
    "        tags_j = frameglasses[j][\"Tags\"]\n",
    "\n",
    "        common_tags = len(tags_i & tags_j)\n",
    "        tags_in_i_not_in_j = len(tags_i - tags_j)\n",
    "        tags_in_j_not_in_i = len(tags_j - tags_i)\n",
    "\n",
    "        min_form = min(common_tags, tags_in_i_not_in_j, tags_in_j_not_in_i)\n",
    "        return i, j, min_form\n",
    "    except Exception as e:\n",
    "        print(f\"Error in worker process: {e}\")\n",
    "        raise\n",
    "\n",
    "def calculate_min_form_tags_fully_parallel(frameglasses):\n",
    "    n = len(frameglasses)\n",
    "    min_form_tags_matrix = np.zeros((n, n))\n",
    "\n",
    "    pair_indices = [(i, j, frameglasses) for i in range(n) for j in range(i + 1, n)]\n",
    "\n",
    "    try:\n",
    "        with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "            results = executor.map(compute_pair, pair_indices)\n",
    "    except Exception as e:\n",
    "        print(\"Falling back to ThreadPoolExecutor due to ProcessPoolExecutor failure.\")\n",
    "        with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "            results = executor.map(compute_pair, pair_indices)\n",
    "\n",
    "    for i, j, min_form in results:\n",
    "        min_form_tags_matrix[i, j] = min_form\n",
    "        min_form_tags_matrix[j, i] = min_form\n",
    "\n",
    "    return min_form_tags_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pair(args):\n",
    "    try:\n",
    "        i, j, frameglasses = args\n",
    "        tags_i = frameglasses[i][\"Tags\"]\n",
    "        tags_j = frameglasses[j][\"Tags\"]\n",
    "\n",
    "        common_tags = len(tags_i & tags_j)\n",
    "        tags_in_i_not_in_j = len(tags_i - tags_j)\n",
    "        tags_in_j_not_in_i = len(tags_j - tags_i)\n",
    "\n",
    "        min_form = min(common_tags, tags_in_i_not_in_j, tags_in_j_not_in_i)\n",
    "        return i, j, min_form\n",
    "    except Exception as e:\n",
    "        print(f\"Error in worker process: {e}\")\n",
    "        raise\n",
    "def compute_pair(args):\n",
    "    try:\n",
    "        i, j, frameglasses = args\n",
    "        tags_i = frameglasses[i][\"Tags\"]\n",
    "        tags_j = frameglasses[j][\"Tags\"]\n",
    "\n",
    "        common_tags = len(tags_i & tags_j)\n",
    "        tags_in_i_not_in_j = len(tags_i - tags_j)\n",
    "        tags_in_j_not_in_i = len(tags_j - tags_i)\n",
    "\n",
    "        min_form = min(common_tags, tags_in_i_not_in_j, tags_in_j_not_in_i)\n",
    "        return i, j, min_form\n",
    "    except Exception as e:\n",
    "        print(f\"Error in worker process: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(frameglasses, output_file_name):\n",
    "    \"\"\"Writes the frameglasses to an output file.\"\"\"\n",
    "    with open(output_file_name, \"w\") as file:\n",
    "        file.write(f\"{len(frameglasses)}\\n\")\n",
    "        for fg in frameglasses:\n",
    "            file.write(\" \".join(map(str, fg[\"Paintings\"])) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_execution_time(func, *args):\n",
    "    \"\"\"Measures the execution time of a function.\"\"\"\n",
    "    start_time = time.time()\n",
    "    result = func(*args)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"{func.__name__} executed in {elapsed_time:.4f} seconds\")\n",
    "    return result, elapsed_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 15:00:18,168 - INFO - Processing Data\\110_oily_portraits.txt...\n",
      "2024-11-20 15:00:18,169 - ERROR - Error processing Data\\110_oily_portraits.txt: [Errno 2] No such file or directory: './Data\\\\Data\\\\110_oily_portraits.txt'\n",
      "2024-11-20 15:00:18,169 - INFO - Processing Data\\11_randomizing_paintings.txt...\n",
      "2024-11-20 15:00:18,171 - ERROR - Error processing Data\\11_randomizing_paintings.txt: [Errno 2] No such file or directory: './Data\\\\Data\\\\11_randomizing_paintings.txt'\n",
      "2024-11-20 15:00:18,171 - INFO - Processing Data\\1_binary_landscapes.txt...\n",
      "2024-11-20 15:00:18,172 - ERROR - Error processing Data\\1_binary_landscapes.txt: [Errno 2] No such file or directory: './Data\\\\Data\\\\1_binary_landscapes.txt'\n",
      "2024-11-20 15:00:18,173 - INFO - Total Global Score: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data\\\\0_example.txt', 'Data\\\\10_computable_moments.txt', 'Data\\\\110_oily_portraits.txt', 'Data\\\\11_randomizing_paintings.txt', 'Data\\\\1_binary_landscapes.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def process_file(input_file, queue=None):\n",
    "    \"\"\"Processes a single file and optionally puts the result in a queue.\"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Processing {input_file}...\")\n",
    "\n",
    "        # Step 1: Parse input\n",
    "        n, paintings = read_input(input_file)\n",
    "        logging.debug(f\"Parsed input: n={n}, paintings={paintings}\")\n",
    "\n",
    "        # Step 2: Create frameglasses\n",
    "        frameglasses = create_frameglasses(paintings)\n",
    "        logging.debug(f\"Created frameglasses: {frameglasses}\")\n",
    "\n",
    "        # Step 3: Calculate score\n",
    "        score = calculate_score(frameglasses)\n",
    "        logging.info(f\"Score for {input_file}: {score}\")\n",
    "\n",
    "        # Step 4: Write the sorted frameglasses to an output file\n",
    "        # Fix the output path to avoid duplicating the DATA_DIR\n",
    "        output_file_name = os.path.normpath(os.path.join(DATA_DIR, f\"{os.path.splitext(os.path.basename(input_file))[0]}_sorted.txt\"))\n",
    "        write_output(frameglasses, output_file_name)\n",
    "        logging.info(f\"Wrote sorted frameglasses to {output_file_name}\")\n",
    "\n",
    "        if queue:\n",
    "            queue.put(score)\n",
    "        return score\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {input_file}: {e}\")\n",
    "        if queue:\n",
    "            queue.put(0)\n",
    "        return 0\n",
    "\n",
    "def main():\n",
    "    # Correctly construct the list of input files\n",
    "    input_files = [os.path.normpath(os.path.join(DATA_DIR, f)) for f in os.listdir(DATA_DIR) if f.endswith(\".txt\")]\n",
    "    \n",
    "    # Separate files into parallel and sequential processing\n",
    "    parallel_files = [f for f in input_files if os.path.basename(f).startswith((\"0\", \"10\"))]\n",
    "    sequential_files = [f for f in input_files if f not in parallel_files]\n",
    "    \n",
    "    total_score = 0\n",
    "    queue = Queue()\n",
    "    processes = []\n",
    "\n",
    "    # Process files in parallel\n",
    "    for input_file in parallel_files:\n",
    "        p = Process(target=process_file, args=(input_file, queue))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    # Wait for all parallel processes to finish\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    # Collect results from parallel processes\n",
    "    while not queue.empty():\n",
    "        total_score += queue.get()\n",
    "\n",
    "    # Process files sequentially\n",
    "    for input_file in sequential_files:\n",
    "        total_score += process_file(input_file)\n",
    "\n",
    "    logging.info(f\"Total Global Score: {total_score}\")\n",
    "\n",
    "    print(input_files)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
